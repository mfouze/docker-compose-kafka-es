version: '3'
services:
  kafka-a-01:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka-a-01
    container_name: kafka-a-01
    ports:
      - "9091:9091"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka-a-01:19091,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9091
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper-a-01:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper-a-01

  kafka-a-02:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka-a-02
    container_name: kafka-a-02
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka-a-02:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-a-01:2181
      KAFKA_BROKER_ID: 2
    depends_on:
      - zookeeper-a-01
  
  kafka-a-03:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka-a-03
    container_name: kafka-a-03
    ports:
      - "9093:9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka-a-03:19093,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper-a-01:2181"
      KAFKA_BROKER_ID: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper-a-01

  zookeeper-a-01:
    image: zookeeper:3.4.9
    hostname: zookeeper-a-01
    container_name: zookeeper-a-01
    ports:
      - "2181:2181"
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
      ZOO_SERVERS: server.1=zookeeper-a-01:2888:3888

  kafdrop-a-01:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop-a-01
    hostname: kafdrop-a-01
    restart: "no"
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka-a-01:19091"
    depends_on:
      - kafka-a-01
      - kafka-a-02
      - kafka-a-03

  postgres-a-01:
    image: postgres:latest
    restart: always
    container_name: postgres-a-01
    hostname: postgres-a-01
    ports:
      - '5432:5432'
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: stats_db
    command: [ 'postgres', '-c', 'wal_level=logical' ]
    healthcheck:
      test: [ 'CMD', 'psql', '-U', 'postgres', '-c', 'SELECT 1' ]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - ./scripts:/docker-entrypoint-initdb.d

  connect-a-01:
    image: confluentinc/cp-kafka-connect:7.3.3
    container_name: connect-a-01
    hostname: connect-a-01
    command:
      - bash
      - -c
      - |
        # Install connector plugins
        # This will by default install into /usr/share/confluent-hub-components/ so make
        #  sure that this path is added to the plugin.path in the environment variables
        confluent-hub  install --no-prompt confluentinc/kafka-connect-elasticsearch:13.1.2
        confluent-hub install --no-prompt debezium/debezium-connector-postgresql:2.2.1   
        confluent-hub install confluentinc/kafka-connect-datagen:0.6.3
        # Launch the Kafka Connect worker
        /etc/confluent/docker/run &
        # Don't exit
        sleep infinity
    depends_on:
      - zookeeper-a-01
      - kafka-a-01
      - kafka-a-02
      - kafka-a-03
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka-a-01:9091,kafka-a-02:9092,kafka-a-03:9093"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: __connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: __connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: __connect-status
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://sr-a-01:8081'
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://sr-a-01:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "connect-a-01"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "3"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "3"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "3"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components/'
      ENABLE_DEBEZIUM_SCRIPTING: 'true'

  sr-a-01:
    image: confluentinc/cp-schema-registry:7.3.3
    container_name: sr-a-01
    hostname: sr-a-01
    restart: always
    depends_on:
      - zookeeper-a-01
      - kafka-a-01
      - kafka-a-02
      - kafka-a-03
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka-a-01:9091,kafka-a-02:9092,kafka-a-03:9093"
      SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: http
      SCHEMA_REGISTRY_HOST_NAME: sr-a-01
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
    ports:
      - 8081:8081

  es-a-01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.13.4
    container_name: es-a-01
    hostname: es-a-01
    restart: always
    environment:
      network.host: 0.0.0.0
      discovery.type: single-node
      cluster.name: es-a-01
      node.name: es-a-01
      xpack.security.enabled: "false"
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
    ports:
      - 9200:9200

  kibana-a-01:
    container_name: kibana-a-01
    hostname: kibana-a-01
    image: docker.elastic.co/kibana/kibana:7.13.4
    restart: unless-stopped
    environment:
      xpack.security.enabled: "false"
      ELASTICSEARCH_HOSTS: http://es-a-01:9200    # address of elasticsearch docker container which kibana will connect
    ports:
      - 5601:5601
    depends_on:
      - es-a-01
    logging:
      options:
        max-size: "${DOCKER_LOGS_MAX_SIZE:-100M}"

  logstash-a-01:
    image: docker.elastic.co/logstash/logstash:7.13.4
    container_name: logstash-a-01
    hostname: logstash-a-01
    depends_on:
      - es-a-01
    ports:
      - 5044:5044
    restart: unless-stopped

  ksqldb-a-01:
    image: confluentinc/ksqldb-server:0.29.0
    hostname: ksqldb-a-01
    container_name: ksqldb-a-01
    depends_on:
      - kafka-a-01
      - kafka-a-02
      - kafka-a-03
      - sr-a-01
    ports:
      - "8088:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka-a-01:9091,kafka-a-02:9092,kafka-a-03:9093
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://sr-a-01:8081
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
